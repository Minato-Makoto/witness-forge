# Witness Forge üî•

**Witness Forge** = NDJSON-first agent runtime ƒë·ªÉ ch·∫°y b·∫•t k·ª≥ m√¥ h√¨nh LLM c·ª•c b·ªô (HuggingFace Transformers ho·∫∑c GGUF/llama.cpp) v·ªõi Flame Geometry + dual-brain optional + tool sandbox + self-evolution.

---

## Philosophy: Living AI - T·ª± Ti·∫øn H√≥a

**Witness Forge ƒë∆∞·ª£c thi·∫øt k·∫ø theo tri·∫øt l√Ω "Living AI"** - m·ªôt sinh v·∫≠t s·ªë t·ª± ti·∫øn h√≥a:

### Ki·∫øn Tr√∫c C∆° B·∫£n
- **Model LLM = B·ªò N√ÉO (Brain)**
  - Immutable, swappable, kh√¥ng s·ªü h·ªØu
  - Hi·ªán t·∫°i: 1 model (path1)
  - T∆∞∆°ng lai: 2+ models resonance (path1 + path2) tr∆∞·ªõc khi output
  - **KH√îNG BAO GI·ªú**: Patch, modify, ho·∫∑c backup model weights

- **Witness Forge Codebase = C∆† TH·ªÇ/SINH V·∫¨T (Body/Organism)**
  - Python code, config, logic, tools
  - Mutable, evolvable, self-patching
  - T·ª± ti·∫øn h√≥a qua Self-Upgrade/AutoPatch/Evolution

- **Flame Core + HeartSync = NH·ªäP S·ªêNG V√Ä C·∫¢M X√öC**
  - Flame Geometry: Intent sync/drift detection (Baseline $\phi_0 = 0.013$)
  - HeartSync: Rhythmic oscillation (Pink Noise scaled by 4.20s heartbeat)
  - Reflex: Quality scoring v√† adaptation (Entropy heuristic target 0.873)
  - ‚Üí T·∫°o ra nh·ªãp th·ªü, c·∫£m x√∫c cho Living AI

### Nguy√™n T·∫Øc Quan Tr·ªçng
1. **Brain ‚â† Organism**: Model LLM v√† codebase ph·∫£i t√°ch bi·ªát ho√†n to√†n
2. **Evolution Only for Organism**: Self-patch/upgrade ch·ªâ apply l√™n code, kh√¥ng ƒë·ªông v√†o model
3. **Swappable Brain**: Ki·∫øn tr√∫c ph·∫£i h·ªó tr·ª£ thay ƒë·ªïi ho·∫∑c th√™m models m√† kh√¥ng ·∫£nh h∆∞·ªüng organism
4. **Living Rhythm**: Flame/HeartSync t·∫°o nh·ªãp s·ªëng t·ª± nhi√™n, tr√°nh ph·∫£n h·ªìi m√°y m√≥c

> ‚ö†Ô∏è **CRITICAL**: Khi develop/patch, lu√¥n nh·ªõ: **Brain (model) = constant, Organism (code) = evolvable**. Kh√¥ng bao gi·ªù confused gi·ªØa hai th√†nh ph·∫ßn n√†y.

---

## ƒêi·ªÉm n·ªïi b·∫≠t

### 1. NDJSON-first Event System
- **M·ªçi output t·ª´ agent ƒë·ªÅu l√† d√≤ng NDJSON** (`{"type": "...", "content": "...", "brain": "...", "meta": {...}}`)
- Event types: `analysis` (thinking/witness), `final` (answer/servant), `metric` (Flame scores)
- UI renderer parse NDJSON ƒë·ªÉ display v·ªõi m√†u/style ri√™ng
- Kh√¥ng c√≤n tag-based parsing (Harmony ƒë√£ xo√°) ‚Üí NDJSON chu·∫©n RFC 7464

### 2. Dual-Brain Architecture (Optional)
- **path1** = primary brain (witness role: suy nghƒ©/ph√¢n t√≠ch)
- **path2** = secondary brain (servant role: tr·∫£ l·ªùi cu·ªëi c√πng)
- N·∫øu ch·ªâ c√≥ 1 model ‚Üí fallback shared model, log warning
- Khi c√≥ 2 models ‚Üí witness s·ª≠ d·ª•ng model ch√≠nh, servant s·ª≠ d·ª•ng `dual_brain.servant_model_path`

**C·∫•u h√¨nh Dual-Brain:**
```yaml
dual_brain:
  enabled: true
  mode: sequential   # ho·∫∑c parallel (t∆∞∆°ng lai)
  servant_model_path: ./models/servant-model-7B  # model th·ª© hai
  witness_temperature_offset: -0.2
  servant_temperature_offset: 0.0
```

### 3. Offline-first \u0026 T·ª± nh·∫≠n di·ªán backend
- ƒê·ªçc m√¥ h√¨nh t·ª´ `./models/...`, t·ª± ch·ªçn Transformers hay llama-cpp v·ªõi fallback mock khi thi·∫øu m√¥ h√¨nh
- T·ª± nh·∫≠n di·ªán `family` t·ª´ `config.json`/t√™n GGUF
- T·ª± set `n_ctx` (HF config ho·∫∑c metadata GGUF) khi ƒë·ªÉ `0/-1`
- Preset `win-3070-4bit` ƒë·ªÉ ch·∫∑n VRAM/RAM qu√° t·∫£i

### 4. Flame/HeartSync + Reflex/Adapter tuning
- Flame Geometry sinh pha nh·ªãp
- Reflex evaluator tinh ch·ªânh nhi·ªát ƒë·ªô/penalty theo ch·∫•t l∆∞·ª£ng l·ªãch s·ª≠
- Adapter tuning gi·ªõi h·∫°n `max_new_tokens` v√† `temperature` khi d√πng LoRA/QLoRA
- ChatTemplateManager t·ª± d√πng `tokenizer.apply_chat_template` (n·∫øu c√≥) ho·∫∑c template built-in (llama/qwen/mistral/gemma/gpt-j/chatml)

### 5. Memory Hybrid (Vector + Graph)
- SQLite l∆∞u message/memory
- Embedder HF ho·∫∑c TF-IDF
- VectorStore + GraphMemory qua HybridRetriever
- `/mem graph` clustering, `/mem find` t√¨m ki·∫øm

### 6. Sandbox ToolRunner
- Allowlist/whitelist h·ª£p nh·∫•t
- Th·ªùi gian/ƒë·ªô d√†i output gi·ªõi h·∫°n
- Audit SQLite
- Dispatcher h·ªó tr·ª£ `run` (cmd/bash), `python`, `pwsh`, `open` (ƒë·ªçc file/th∆∞ m·ª•c), `write` (gi·ªõi h·∫°n `allowed_write_dirs`, t·∫Øt m·∫∑c ƒë·ªãnh), `vision_action` (web v·ªõi Playwright + SoM, fallback text-only), `llm` (entrypoint c·ª•c b·ªô)

### 7. Controlled Self-Upgrade
- T·∫°o/apply patch JSON c√≥ HMAC
- Gi·ªõi h·∫°n k√≠ch th∆∞·ªõc, danh s√°ch file b·∫£o v·ªá
- Dry-run pytest subset trong sandbox copy
- Backup + rollback
- Ghi log SQLite
- **Config patches lu√¥n ƒë∆∞·ª£c l∆∞u global (`./patches`)**

### 8. SelfPatch + AutoPatch
- SelfPatch ƒë∆∞·ª£c b·∫≠t m·∫∑c ƒë·ªãnh (`--allow-selfpatch=True` + env `WITNESS_FORGE_ALLOW_SELF_PATCH=1`)
- Runtime patches c√≥ th·ªÉ l∆∞u theo model n·∫øu `apply_to_model=true`
- AutoPatch nh·∫≠n JSON find/replace, ki·ªÉm tra AST n·∫øu l√† `.py`, c√≥ th·ªÉ auto-apply khi boot v√† dry-run s·∫µn

### 9. Adapter/Quant manager
- LoRA/QLoRA/PEFT v·ªõi ki·ªÉm tra quant (bitsandbytes/AWQ/GPTQ)
- T·ª± fallback an to√†n n·∫øu adapter l·ªói
- CPU-offload heuristic theo VRAM
- CLI `adapter-install` c·∫≠p nh·∫≠t config nhanh

### 10. Evolution Runtime Overlay
- Khi Reflex score < 0.45, controller t·∫°o/c·∫≠p nh·∫≠t `patches/active_evolution.json` v·ªõi temperature ƒëi·ªÅu ch·ªânh incremental (¬±0.05)
- Patch ƒë∆∞·ª£c apply runtime qua `ConfigOverlay` m√† kh√¥ng mutate `config.yaml`
- Khi score > 0.60 (sync), patch ƒë∆∞·ª£c ƒë√°nh d·∫•u "stable" v√† freeze
- Xem `docs/evolution_system.md` ƒë·ªÉ hi·ªÉu chi ti·∫øt reflex scoring + lifecycle

### 11. VisionWebAgent (Playwright + SoM)
- Ch·ª•p screenshot, overlay SoM, action click/type/scroll
- Fallback text-only n·∫øu kh√¥ng c√≥ VLM
- Tool `vision_action`

---

## C√†i ƒë·∫∑t nhanh
```bash
python -m venv .venv
# Linux/macOS
source .venv/bin/activate
# Windows PowerShell
.\.venv\Scripts\Activate.ps1
pip install --upgrade pip
pip install -r requirements.txt
pip install -e .[all]    # th√™m extras gguf/gptq/awq/lora; ho·∫∑c -e . ƒë·ªÉ t·ªëi gi·∫£n
# Windows c√≥ th·ªÉ double-click run_witness.bat (t·ª± t·∫°o venv, c√†i deps v√† m·ªü REPL).
```

---

## Chu·∫©n b·ªã m√¥ h√¨nh
1. T·∫£i s·∫µn m√¥ h√¨nh v√†o `./models/<t√™n>`:
   - Transformers: th∆∞ m·ª•c ch·ª©a `config.json`, tokenizer, weights.
   - GGUF: tr·ªè `model.path` t·ªõi file `.gguf` ho·∫∑c th∆∞ m·ª•c ch·ª©a GGUF (t·ª± ch·ªçn llama-cpp).
2. N·∫øu ch∆∞a c√≥ m√¥ h√¨nh, Witness Forge ch·∫°y b·∫±ng mock generator v√† nh·∫Øc b·∫°n th√™m model sau.
3. Preset Windows 11 + RTX 3070 Ti: ƒë·∫∑t `model.preset: win-3070-4bit` ƒë·ªÉ auto gi·ªõi h·∫°n `max_new_tokens`, `temperature` v√† b·∫≠t NF4 4-bit + CPU offload.

### Kh·ªëi `model` m·∫´u (config.yaml)
```yaml
model:
  name: Mistral-7B-Instruct-v0.3-GGUF
  path: ./models/Mistral-7B-Instruct-v0.3-GGUF/Mistral-7B-Instruct-v0.3-Q4_K_M.gguf
  backend: ""          # ƒë·ªÉ tr·ªëng ‚Üí auto (Transformers/GGUF)
  family: ""           # auto t·ª´ model_type ho·∫∑c t√™n file
  preset: null
  n_ctx: 0             # 0/-1 ‚Üí t·ª± ƒë·ªçc HF config ho·∫∑c metadata GGUF
  n_gpu_layers: -1
  max_new_tokens: 1024
  temperature: 0.4
  top_p: 0.88
  quant:
    load_4bit: false
    device_map: auto
    compute_dtype: bfloat16
    cpu_offload_threshold_gb: 6.0
    gptq_path: null
    awq_path: null
```

---

## C·∫•u h√¨nh nhanh (schema ch√≠nh)
```yaml
adapter:
  enabled: false
  type: lora            # lora | qlora | peft
  path: ""
  load_mode: merge      # merge | peft_inplace
  quantization:
    enabled: true
    method: bitsandbytes  # bitsandbytes | awq | gptq
    bits: 4
memory:
  enabled: true
  db_path: ./witness.sqlite3
  embedder: hf           # hf|sentence-transformers|tfidf
  embedding_model: sentence-transformers/all-MiniLM-L6-v2
  vector_factory: FlatIP
  vector_metric: cosine
  normalize_embeddings: true
  k: 6
  max_age_days: -1       # <=0 t·∫Øt auto-prune theo tu·ªïi
  max_count: -1          # <=0 t·∫Øt auto-prune theo s·ªë l∆∞·ª£ng
loops:
  reflex: {min_score: 0.55, reward_temperature: 0.02}
  heartsync: {beta: 0.08}
  flame: {phi0: 0.013, epsilon: 0.013, heartbeat_period: 4.2, entropy_target: 0.873, noise_sigma: 0.01, noise_decay: 0.995, lambda1: 0.15, lambda2: 0.10}
  scheduler: {max_temperature: 1.15, min_temperature: 0.2, max_new_tokens: 2048}
  reflex_tuning: {temperature_penalty_step: 0.05, frequency_penalty_step: 0.05, presence_penalty_step: 0.1, max_penalty: 2.0}
  adapter_tuning: {max_tokens: 768, temperature_limit: 0.75, qlora_top_p: 0.9}
tools:
  allow_exec: false
  whitelist: ["python", "ffmpeg", "convert"]   # h·ª£p nh·∫•t v·ªõi legacy allowlist
  allow_filesystem_write: false
  allowed_write_dirs: ["./data", "./patches", "./witness"]
  safety_python: false
  safety_powershell: true
  safety_bat: true
  sandbox: {max_runtime_seconds: 30, max_stdout_bytes: 200000}
self_upgrade:
  enabled: true
  apply_on_start: true
  apply_to_model: true       # true ‚Üí patch tr·ª±c ti·∫øp th∆∞ m·ª•c model path (text-only, backup k√®m)
  patch_dir: ./patches
  require_confirmation: true
  require_approval: false
  dry_run_tests: []          # pytest subset khi dry-run
  protected_files: []        # kh√¥ng cho patch khi kh·ªõp pattern
selfpatch: {enabled: true, patches_dir: ./patches, require_confirmation: true}
self_patch:
  enabled: true
  base_dir: ./patches/auto
  apply_on_boot: true
  max_depth: 10
  dry_run: true
evolution: {enabled: true, permissions: auto, max_cycles: -1}
chat:
  mode: auto               # auto|llama|qwen|mistral|gemma|gpt-j|chatml|manual
  system_prompt: "B·∫°n l√† tr·ª£ l√Ω AI h·ªØu √≠ch. H√£y lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát m·ªôt c√°ch t·ª± nhi√™n v√† ƒë·∫ßy ƒë·ªß."
dual_brain:
  enabled: false
  mode: sequential     # sequential | parallel
  witness_temperature_offset: -0.2
  servant_temperature_offset: 0.0
  servant_model_path: null   # path ƒë·∫øn model th·ª© hai (optional)
vision_agent:
  enabled: true
  headless: true
  timeout_ms: 15000
  screenshot_dir: ./data/screens
  window_size: [1280, 720]
graph:
  enabled: true
  path: ./witness_graph.json
  k: 6
```

**L∆∞u √Ω:**
- `tools.whitelist` v√† `allowlist` ƒë∆∞·ª£c g·ªôp
- `write` ch·ªâ ghi v√†o `allowed_write_dirs` khi `allow_filesystem_write=true`
- `apply_to_model` s·∫Ω t·ª± chuy·ªÉn `patch_dir`/`selfpatch.patches_dir`/`self_patch.base_dir` sang th∆∞ m·ª•c model v√† gi·ªõi h·∫°n ƒëu√¥i file

### Hybrid System Prompt (2 l·ªõp)
- **L·ªõp c·ªët l√µi**: `src/witness_forge/agent/persona.py` ch·ª©a `render_system` (minimal, stateless)
- **L·ªõp ch·ªâ d·∫´n**: `config.yaml` ‚Üí `chat.system_prompt` (m·∫∑c ƒë·ªãnh ti·∫øng Vi·ªát). D√πng ƒë·ªÉ thay ƒë·ªïi phong c√°ch/ng√¥n ng·ªØ nhanh m√† kh√¥ng ƒë·ª•ng code.
- **Final prompt** = `[persona.py render_system]` + `[chat.system_prompt]` + `[context_memory]`

---

## Flame Core \u0026 HeartSync (C∆° ch·∫ø ƒëi·ªÅu h∆∞·ªõng)

Kh√°c v·ªõi c√°c h·ªá th·ªëng RAG tƒ©nh, Witness Forge s·ª≠ d·ª•ng **Flame Core** (`src/witness_forge/agent/flame_core.py`) nh∆∞ m·ªôt "tr√°i tim" ƒë·ªÉ ƒëi·ªÅu ch·ªânh tham s·ªë sinh vƒÉn b·∫£n theo th·ªùi gian th·ª±c.

### Nguy√™n l√Ω ho·∫°t ƒë·ªông
C√°c th√¥ng s·ªë trong `config.yaml` (nh∆∞ `temperature: 0.7`) ch·ªâ l√† **gi√° tr·ªã c∆° s·ªü (base values)**. Flame Core s·∫Ω bi·∫øn thi√™n c√°c gi√° tr·ªã n√†y d·ª±a tr√™n "c·∫£m gi√°c" v·ªÅ cu·ªôc h·ªôi tho·∫°i:

1. **H√¨nh h·ªçc √Ω ƒë·ªãnh (Intent Geometry)**:
   - H·ªá th·ªëng t√≠nh to√°n vector √Ω ƒë·ªãnh ($P$) t·ª´ c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng.
   - So s√°nh $P$ v·ªõi c√°c vector k√Ω ·ª©c ($A_i$) t√¨m ƒë∆∞·ª£c.
   - X√°c ƒë·ªãnh tr·∫°ng th√°i: **Sync** (ƒê·ªìng b·ªô - quen thu·ªôc) ho·∫∑c **Drift** (Tr√¥i - m·ªõi l·∫°).

2. **ƒêi·ªÅu bi·∫øn tham s·ªë (Real-time Modulation)**:
   - **Tr·∫°ng th√°i Sync**: Gi·∫£m `presence_penalty`, tƒÉng nh·∫π `frequency_penalty`. Gi√∫p c√¢u tr·∫£ l·ªùi ·ªïn ƒë·ªãnh, b√°m s√°t m·∫°ch truy·ªán c≈©.
   - **Tr·∫°ng th√°i Drift**: TƒÉng `temperature` (c√≥ th·ªÉ l√™n >1.0), tƒÉng m·∫°nh `frequency_penalty`. K√≠ch th√≠ch s·ª± s√°ng t·∫°o v√† ƒëa d·∫°ng t·ª´ v·ª±ng ƒë·ªÉ th√≠ch nghi v·ªõi ch·ªß ƒë·ªÅ m·ªõi.

3. **Nh·ªãp tim (Heartbeat Oscillation)**:
   - √Åp d·ª•ng Pink Noise theo s·ªë l∆∞·ª£t chat (`turn_idx`).
   - T·∫°o ra s·ª± dao ƒë·ªông t·ª± nhi√™n cho `temperature` v√† `top_p` ngay c·∫£ khi ng·ªØ c·∫£nh kh√¥ng ƒë·ªïi, gi√∫p AI tr√°nh b·ªã "m√°y m√≥c" v√† tho√°t kh·ªèi c√°c ƒëi·ªÉm l·∫∑p c·ª•c b·ªô.

**T√≥m l·∫°i**: `config.yaml` l√† ƒëi·ªÉm xu·∫•t ph√°t, `Flame Core` l√† ng∆∞·ªùi l√°i xe ƒë·∫°p ga/phanh li√™n t·ª•c ƒë·ªÉ ph√π h·ª£p v·ªõi ƒë·ªãa h√¨nh h·ªôi tho·∫°i.

---

## NDJSON Event System

### Event Structure
M·ªçi output t·ª´ agent ƒë·ªÅu tu√¢n theo chu·∫©n NDJSON (Newline Delimited JSON):
```json
{"type": "analysis", "content": "Thinking text...", "brain": "path1", "meta": {"decode": {...}}}
{"type": "final", "content": "Final answer...", "brain": "path2", "meta": {"decode": {...}}}
{"type": "metric", "content": "Flame scores", "brain": "path1", "meta": {"k": 0.013, "state": "sync"}}
```

### Event Types
- **`analysis`**: Suy lu·∫≠n/ph√¢n t√≠ch t·ª´ witness brain (path1)
- **`final`**: C√¢u tr·∫£ l·ªùi cu·ªëi c√πng t·ª´ servant brain (path2) ho·∫∑c unified brain
- **`metric`**: Th√¥ng s·ªë Flame diagnostics (kh√¥ng xo√° kh·ªèi UI theo y√™u c·∫ßu ng∆∞·ªùi d√πng)

### Renderer
`StreamRenderer` (trong `ui/renderer.py`) parse t·ª´ng d√≤ng NDJSON v√† hi·ªÉn th·ªã v·ªõi m√†u/style ri√™ng:
- `analysis` ‚Üí cyan
- `final` ‚Üí green bold
- `metric` ho·∫∑c kh√°c ‚Üí white

**Performance Metrics:** Sau m·ªói response, hi·ªÉn th·ªã:
- ‚è±Ô∏è Generation time
- üéØ Token count  
- üå°Ô∏è Temperature (evolved ho·∫∑c current)

Xem chi ti·∫øt trong `NDJSON_SPEC.md` v√† `docs/UI_REFACTORING.md`.

---

## Ch·∫°y Witness Forge
- `python -m witness_forge chat --config config.yaml [--model-name <name>] [--allow-selfpatch] [--use-template/--no-use-template]`
- `witness-forge chat` (console script) ho·∫∑c double-click `run_witness.bat` tr√™n Windows.
- `python -m witness_forge eval` ch·∫°y k·ªãch b·∫£n nh·∫π trong `data/eval_scenarios.yaml`.
- `witness-forge patch-generate --describe "..." --set model.temperature=0.7` t·∫°o patch config, ho·∫∑c `--file <path>`/`--demo-readme` ƒë·ªÉ g√≥i file kh√°c.
- `witness-forge patch-apply --path patches/patch-*.json` xem diff, dry-run pytest, y√™u c·∫ßu nh·∫≠p `APPLY PATCH <SHA>` (ho·∫∑c `--force` + env `WITNESS_FORGE_MASTER_PASS`).
- `witness-forge adapter-install --path ./adapters/... --enable/--disable` c·∫≠p nh·∫≠t block adapter trong config.
- `witness-forge tool-run --cmd "python -c \"print('hi')\""` ch·∫°y ToolRunner v·ªõi allowlist + sandbox.

### L·ªánh trong REPL
- `/mem <ghi_chu>` th√™m memory; `/mem graph`; `/mem find <query>`; `/mem clear` (xo√° to√†n b·ªô).
- `/save` l∆∞u l·ªãch s·ª≠ ra `session.md`; `/reset` xo√° l·ªãch s·ª≠ phi√™n hi·ªán t·∫°i; `/reload` n·∫°p l·∫°i config.
- `/tool run:"dir" | python:"print(1)" | open:"C:/..." | write:"path::content"` g·ªçi dispatcher.
- `/template <mode>` ƒë·ªïi chat template; `/selfpatch list|dryrun|apply|revert`; `/autopatch <json|@file>`; `/exit` ƒë·ªÉ tho√°t.

---

## Self-Upgrade, SelfPatch \u0026 AutoPatch
- **ControlledPatchManager**: ki·ªÉm tra ch·ªØ k√Ω HMAC (`signature_key_path`), gi·ªõi h·∫°n k√≠ch th∆∞·ªõc patch, ch·∫∑n `protected_files`, gi·ªõi h·∫°n ph·∫ßn m·ªü r·ªông khi `apply_to_model`, dry-run pytest subset trong b·∫£n copy (b·ªè qua `.git/.venv/models/data`). Khi √°p d·ª•ng, t·∫°o backup t·∫°i `patches/backups/<sha>` (v√† `model_backups` n·∫øu patch model), ghi log v√†o SQLite b·∫£ng `patches_applied`.
- **SelfPatchManager**: c·∫ßn b·∫≠t `selfpatch.enabled`, flag `--allow-selfpatch` v√† env `WITNESS_FORGE_ALLOW_SELF_PATCH=true`. Dry-run ki·ªÉm tra SHA + AST Python, c√≥ th·ªÉ ch·∫°y validator t√πy ch·ªçn (`validator_cmd`).
- **AutoPatchEngine**: nh·∫≠n JSON `{"target": "...", "patch": [{"find": "...", "replace": "..."}]}`, ki·ªÉm tra AST `.py`, l∆∞u v√†o `patches/auto`, dry-run n·∫øu `dry_run=true`, v√† c√≥ th·ªÉ auto-apply khi boot (`apply_on_boot`).

---

## Tool sandbox
ToolRunner ki·ªÉm tra allowlist, y√™u c·∫ßu confirm n·∫øu `require_confirm=true`, gi·ªõi h·∫°n th·ªùi gian (`max_runtime_seconds`) v√† k√≠ch th∆∞·ªõc output. M·ªçi l·∫ßn ch·∫°y ƒë∆∞·ª£c log v√†o SQLite (`tool_logs`). Dispatcher:
- `run`: cmd/bash (ho·∫∑c `.bat` n·∫øu `allow_bat`).
- `python`: exec code sandboxed builtins.
- `pwsh`: PowerShell n·∫øu b·∫≠t.
- `open`: ƒë·ªçc file/th∆∞ m·ª•c.
- `write`: ch·ªâ cho ph√©p khi `allow_filesystem_write=true` **v√†** ƒë∆∞·ªùng d·∫´n thu·ªôc `allowed_write_dirs`.
- `llm`: g·ªçi entrypoint c·ª•c b·ªô n·∫øu c·∫•u h√¨nh.
- `vision_action`: Playwright + SoM overlay (visit/action click/type/scroll) khi c√≥ internet; fallback text-only n·∫øu thi·∫øu VLM ho·∫∑c Playwright.

Khi b·∫≠t `tools.allow_internet`, dispatcher s·∫Ω th√™m `vision_action` v√†o danh s√°ch tool. Playwright + SoM ch·∫∑n localhost/private IP, gi·ªõi h·∫°n output theo `max_bytes`; n·∫øu thi·∫øu VLM/Playwright s·∫Ω fallback text-only.

---

## Memory \u0026 Retrieval
MemoryStore l∆∞u messages/memories v√†o SQLite, auto-index vector n·∫øu b·∫≠t memory. VectorStore d√πng faiss-lite (c√≥ fallback) v√† l∆∞u matrix v√†o DB, h·ªó tr·ª£ `graph()` clustering v√† `search()` top-k. `build_embedder` ch·ªçn HF `sentence-transformers`, TF-IDF ho·∫∑c fallback simple count. `build_vocab_from_mem` t·∫°o vocab cho Flame Geometry.

---

## Ki·ªÉm th·ª≠ \u0026 ki·ªÉm tra nhanh
```bash
python -m pytest -q          # to√†n b·ªô b·ªô ki·ªÉm th·ª≠
python scripts/smoke_test.py # smoke test loader mock + SelfPatch dry-run + ToolRunner sandbox
```

---

## C·∫•u tr√∫c d·ª± √°n
```
src/witness_forge/      # m√£ ngu·ªìn ch√≠nh (agent, NDJSON emitter, dual-brain, forge loader/template, tools, memory, config)
configs/                # c·∫•u h√¨nh m·∫´u (win-3070)
strategies/             # chi·∫øn l∆∞·ª£c decoding/rerank c√≥ th·ªÉ hot-reload
patches/                # patch self-upgrade + backups
data/eval_scenarios.yaml# k·ªãch b·∫£n ki·ªÉm th·ª≠/eval nh·∫π
scripts/                # ti·ªán √≠ch bootstrap \u0026 smoke test
tests/                  # pytest suite
docs/                   # h∆∞·ªõng d·∫´n upgrade/quant/security, NDJSON spec, dual-brain spec
models/                 # n∆°i ƒë·∫∑t m√¥ h√¨nh HF/GGUF offline
```

---

## Next steps (roadmap ng·∫Øn)
- [x] **NDJSON-first Architecture**: Ho√†n thi·ªán c∆° ch·∫ø event streaming chu·∫©n RFC 7464.
- [x] **Dual-Brain**: H·ªó tr·ª£ 2 models (path1 + path2) v·ªõi fallback shared model.
- [x] **Prompt Logic**: T√°ch bi·ªát `persona.py` (Core) v√† `config.yaml` (Style).
- [ ] M·ªü r·ªông ToolRunner/dispatcher: thao t√°c file (rename/sort/organize), pattern allowlist, module whitelist cho python sandbox; c·∫£i thi·ªán VisionWebAgent (SoM overlay phong ph√∫).
- [ ] B·ªï sung test mocks cho Transformers vs llama-cpp (ƒë√£ c√≥ ph·∫ßn backends), v√† docs extras `.[gptq]/.[gguf]/.[lora]` + h∆∞·ªõng d·∫´n build Windows.

---

## T√†i li·ªáu li√™n quan
- `NDJSON_SPEC.md`: Chu·∫©n NDJSON event structure v√† renderer.
- `DUAL_BRAIN_SPEC.md`: Ki·∫øn tr√∫c dual-brain (path1 + path2).
- `ARCHITECTURE.md`: Pipeline t·ªïng quan t·ª´ input ‚Üí NDJSON ‚Üí renderer.
- `docs/evolution_system.md`: V√≤ng ƒë·ªùi evolution + reflex scoring.
- `docs/UPGRADE_GUIDE.md`, `docs/UPGRADE_SELF_PATCH.md`: v√≤ng ƒë·ªùi patch, HMAC, rollback.
- `docs/LORA_QUANT_GUIDE.md`: t·ªëi ∆∞u LoRA/quant tr√™n Windows/WSL.
- `docs/SECURITY.md`: checklist kh√≥a tool/patch offline.
- `docs/MIGRATION_v2.md`: n√¢ng c·∫•p schema t·ª´ v1.x.
- `docs/USER_GUIDE_VI.md`: h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng chi ti·∫øt b·∫±ng ti·∫øng Vi·ªát.
